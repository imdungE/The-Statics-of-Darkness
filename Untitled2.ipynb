{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5698e37-8972-430f-9b83-6f7cb8f6b90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== ìƒê¸°ë¶€ í™œë™ í‚¤ì›Œë“œ ë¶„ì„ ì‹œì‘ =====\n",
      "\n",
      "--- ìœ„ì•„ì¤€ìƒê¸°ë¶€OCR_ì°½ì˜ì í™œë™ë³¸.csv ë¶„ì„ ì‹œì‘ ---\n",
      "ê°ì§€ëœ ì¸ì½”ë”©: EUC-KR\n",
      "CSV ë¡œë”© ì„±ê³µ! ì‚¬ìš© ì¸ì½”ë”© = EUC-KR\n",
      "\n",
      "--- ì„±í™ê²½ìƒê¸°ë¶€OCR_ì°½ì˜ì í™œë™ë³¸.csv ë¶„ì„ ì‹œì‘ ---\n",
      "ê°ì§€ëœ ì¸ì½”ë”©: EUC-KR\n",
      "CSV ë¡œë”© ì„±ê³µ! ì‚¬ìš© ì¸ì½”ë”© = EUC-KR\n",
      "\n",
      "--- ìµœí˜„ì¤€ìƒê¸°ë¶€OCR_ì°½ì˜ì í™œë™ë³¸.csv ë¶„ì„ ì‹œì‘ ---\n",
      "ê°ì§€ëœ ì¸ì½”ë”©: EUC-KR\n",
      "CSV ë¡œë”© ì„±ê³µ! ì‚¬ìš© ì¸ì½”ë”© = EUC-KR\n",
      "\n",
      "--- ê¹€ë™í•˜ìƒê¸°ë¶€OCR_ì°½ì˜ì í™œë™ë³¸.csv ë¶„ì„ ì‹œì‘ ---\n",
      "ê°ì§€ëœ ì¸ì½”ë”©: EUC-KR\n",
      "CSV ë¡œë”© ì„±ê³µ! ì‚¬ìš© ì¸ì½”ë”© = EUC-KR\n",
      "\n",
      "==========================================================================================\n",
      "===== íŒŒì¼ë³„ ìµœì¢… ìš”ì•½ ê²°ê³¼ =====\n",
      "==========================================================================================\n",
      "íŒŒì¼ëª…                            ìƒíƒœ         ì´ í‚¤ì›Œë“œ ìˆ˜         ì´ ë‹¨ì–´ ìˆ˜          ë§¤ì¹­ í‚¤ì›Œë“œ ì˜ˆì‹œ (ìµœëŒ€ 5ê°œ)\n",
      "------------------------------------------------------------------------------------------\n",
      "ìœ„ì•„ì¤€ìƒê¸°ë¶€OCR_ì°½ì˜ì í™œë™ë³¸.csv           âœ… ì„±ê³µ       48              1570            ì°½ì˜, í”„ë¡œì íŠ¸, íŠ¹ê°•, íƒìƒ‰, í”„ë¡œê·¸ë¨\n",
      "ì„±í™ê²½ìƒê¸°ë¶€OCR_ì°½ì˜ì í™œë™ë³¸.csv           âœ… ì„±ê³µ       46              1499            ì „ê³µ, ì—°êµ¬, ì°½ì˜, í”„ë¡œì íŠ¸, íƒìƒ‰\n",
      "ìµœí˜„ì¤€ìƒê¸°ë¶€OCR_ì°½ì˜ì í™œë™ë³¸.csv           âœ… ì„±ê³µ       53              1561            ì „ê³µ, ì—°êµ¬, ì°½ì˜, í”„ë¡œì íŠ¸, íŠ¹ê°•\n",
      "ê¹€ë™í•˜ìƒê¸°ë¶€OCR_ì°½ì˜ì í™œë™ë³¸.csv           âœ… ì„±ê³µ       34              1319            ì „ê³µ, ì²´í—˜êµì‹¤, ì—°êµ¬, ì°½ì˜, íŠ¹ê°•\n",
      "------------------------------------------------------------------------------------------\n",
      "ğŸ”¥ ëª¨ë“  íŒŒì¼ì˜ í‚¤ì›Œë“œ ì´í•© (ì „ì²´ ë°œìƒ íšŸìˆ˜): 181 ê°œ\n",
      "ğŸ”¥ ëª¨ë“  íŒŒì¼ì˜ ë°ì´í„° ì´ ë‹¨ì–´ ìˆ˜ (ì „ì²´ í•©ì‚°): 5949 ë‹¨ì–´\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import chardet\n",
    "import pandas as pd\n",
    "import re\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# 1. íŒŒì¼ ê²½ë¡œ ëª©ë¡ ì •ì˜\n",
    "filepaths = [\n",
    "    \"data/ìœ„ì•„ì¤€ìƒê¸°ë¶€OCR_ì°½ì˜ì í™œë™ë³¸.csv\",\n",
    "    \"data/ì„±í™ê²½ìƒê¸°ë¶€OCR_ì°½ì˜ì í™œë™ë³¸.csv\",\n",
    "    \"data/ìµœí˜„ì¤€ìƒê¸°ë¶€OCR_ì°½ì˜ì í™œë™ë³¸.csv\",\n",
    "    \"data/ê¹€ë™í•˜ìƒê¸°ë¶€OCR_ì°½ì˜ì í™œë™ë³¸.csv\"\n",
    "]\n",
    "\n",
    "# 2. ë¶„ì„ì— ì‚¬ìš©í•  í‚¤ì›Œë“œ ì •ì˜\n",
    "keywords = [\n",
    "    \"ì§„ë¡œ\", \"ì „ê³µ\", \"ì§ì—…\", \"íƒìƒ‰\", \"ìœµí•©\", \"ì‹¬í™”\", \"ë¶€ìŠ¤\", \"í•œë§ˆë‹¹\", \n",
    "    \"ì›Œí¬ìˆ\", \"ì²´í—˜êµì‹¤\", \"íŠ¹ê°•\", \"ê°•ì¢Œ\", \"ì„¸ë¯¸ë‚˜\", \"í”„ë¡œê·¸ë¨\", \n",
    "    \"ê³µëª¨ì „\", \"ë°œí‘œíšŒ\", \"ì†Œë…¼ë¬¸\", \"ë³´ê³ ì„œ\", \"ì—°êµ¬\", \n",
    "    \"ì„¤ê³„\", \"í”„ë¡œì íŠ¸\", \"ì°½ì˜\"\n",
    "]\n",
    "\n",
    "# ì •ê·œì‹ íŒ¨í„´ ìƒì„±\n",
    "pattern = \"(\" + \"|\".join(keywords) + \")\"\n",
    "\n",
    "# 3. íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜\n",
    "def process_file(filepath: str, pattern: str) -> Dict[str, Any]:\n",
    "    file_name = os.path.basename(filepath)\n",
    "    result = {\"File\": file_name, \"Status\": \"Processing\", \"Total Keywords\": 0, \"Total Word Count\": 0, \"Matched Examples\": []}\n",
    "\n",
    "    # 3.1 ê²½ë¡œ ì²´í¬\n",
    "    if not os.path.exists(filepath):\n",
    "        result[\"Status\"] = \"âŒ íŒŒì¼ ì—†ìŒ\"\n",
    "        return result\n",
    "\n",
    "    # 3.2 ì¸ì½”ë”© ìë™ ê°ì§€\n",
    "    enc = None\n",
    "    try:\n",
    "        with open(filepath, \"rb\") as f:\n",
    "            raw = f.read(200000)\n",
    "            detected = chardet.detect(raw)\n",
    "            enc = detected[\"encoding\"]\n",
    "    except Exception:\n",
    "        result[\"Status\"] = \"âŒ ì¸ì½”ë”© ê°ì§€ ì‹¤íŒ¨\"\n",
    "        return result\n",
    "    \n",
    "    print(f\"\\n--- {file_name} ë¶„ì„ ì‹œì‘ ---\")\n",
    "    print(f\"ê°ì§€ëœ ì¸ì½”ë”©: {enc}\")\n",
    "\n",
    "    # 3.3 CSV ë¡œë”© ì‹œë„\n",
    "    df = None\n",
    "    encodings = [enc, \"utf-8\", \"utf-8-sig\", \"cp949\", \"euc-kr\"]\n",
    "    for e in encodings:\n",
    "        try:\n",
    "            df = pd.read_csv(filepath, encoding=e)\n",
    "            print(f\"CSV ë¡œë”© ì„±ê³µ! ì‚¬ìš© ì¸ì½”ë”© = {e}\")\n",
    "            break\n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    if df is None:\n",
    "        result[\"Status\"] = \"âŒ CSV ë¡œë”© ì‹¤íŒ¨\"\n",
    "        return result\n",
    "\n",
    "    # 3.4 í…ìŠ¤íŠ¸ ì»¬ëŸ¼ í†µí•©\n",
    "    text_columns = df.select_dtypes(include=[\"object\"]).columns\n",
    "    if len(text_columns) == 0:\n",
    "        result[\"Status\"] = \"âŒ ë¶„ì„í•  í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì—†ìŒ\"\n",
    "        return result\n",
    "        \n",
    "    df[\"__merged_text__\"] = df[text_columns].fillna(\"\").astype(str).agg(\" \".join, axis=1)\n",
    "\n",
    "    # --- ì´ ë‹¨ì–´ ìˆ˜ ê³„ì‚° ---\n",
    "    full_text = \" \".join(df[\"__merged_text__\"].astype(str))\n",
    "    # ê³µë°± ê¸°ì¤€ìœ¼ë¡œ ë‹¨ì–´ë¥¼ ë¶„ë¦¬í•˜ì—¬ ê°œìˆ˜ë¥¼ ì…‰ë‹ˆë‹¤.\n",
    "    total_word_count = len(full_text.split())\n",
    "    # -----------------------\n",
    "\n",
    "    # 3.5 í‚¤ì›Œë“œ ë§¤ì¹­ëœ í™œë™ ì´ ê°œìˆ˜ ì¶”ì¶œ\n",
    "    all_matched_keywords = []\n",
    "    \n",
    "    for text in df[\"__merged_text__\"]:\n",
    "        matches = re.findall(pattern, text)\n",
    "        all_matched_keywords.extend(matches)\n",
    "\n",
    "    total_keywords = len(all_matched_keywords)\n",
    "    \n",
    "    all_unique_keyword_types = list(set(all_matched_keywords))\n",
    "    \n",
    "    result[\"Status\"] = \"âœ… ì„±ê³µ\"\n",
    "    result[\"Total Keywords\"] = total_keywords\n",
    "    result[\"Total Word Count\"] = total_word_count # ìƒˆë¡œìš´ ì¸¡ì • í•­ëª© ì¶”ê°€\n",
    "    result[\"Matched Examples\"] = all_unique_keyword_types[:5]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# 4. ë£¨í”„ ì‹¤í–‰ ë° ê²°ê³¼ ì¶œë ¥\n",
    "print(\"===== ìƒê¸°ë¶€ í™œë™ í‚¤ì›Œë“œ ë¶„ì„ ì‹œì‘ =====\")\n",
    "summary_results = []\n",
    "grand_total_keywords = 0\n",
    "grand_total_words = 0 # ì „ì²´ ë‹¨ì–´ ì´í•©ì„ ìœ„í•œ ë³€ìˆ˜ ì¶”ê°€\n",
    "\n",
    "for fp in filepaths:\n",
    "    summary = process_file(fp, pattern)\n",
    "    summary_results.append(summary)\n",
    "    \n",
    "    # ì„±ê³µì ìœ¼ë¡œ ë¶„ì„ëœ ê²½ìš°ì—ë§Œ ì „ì²´ í•©ì‚°ì— ì¶”ê°€\n",
    "    if summary[\"Status\"] == \"âœ… ì„±ê³µ\":\n",
    "        grand_total_keywords += summary[\"Total Keywords\"]\n",
    "        grand_total_words += summary[\"Total Word Count\"]\n",
    "\n",
    "\n",
    "# 5. ìµœì¢… ìš”ì•½ ì¶œë ¥\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"===== íŒŒì¼ë³„ ìµœì¢… ìš”ì•½ ê²°ê³¼ =====\")\n",
    "print(\"=\"*90)\n",
    "# ì¶œë ¥ í¬ë§· ìˆ˜ì •: 'ì´ ë‹¨ì–´ ìˆ˜' ì»¬ëŸ¼ ì¶”ê°€\n",
    "print(\"{:<30} {:<10} {:<15} {:<15} {:<}\".format(\"íŒŒì¼ëª…\", \"ìƒíƒœ\", \"ì´ í‚¤ì›Œë“œ ìˆ˜\", \"ì´ ë‹¨ì–´ ìˆ˜\", \"ë§¤ì¹­ í‚¤ì›Œë“œ ì˜ˆì‹œ (ìµœëŒ€ 5ê°œ)\"))\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for res in summary_results:\n",
    "    samples = ', '.join(res[\"Matched Examples\"])\n",
    "    if res[\"Status\"] == \"âœ… ì„±ê³µ\":\n",
    "        print(\"{:<30} {:<10} {:<15} {:<15} {:<}\".format(\n",
    "            res[\"File\"], res[\"Status\"], res[\"Total Keywords\"], res[\"Total Word Count\"], samples\n",
    "        ))\n",
    "    else:\n",
    "        # ì‹¤íŒ¨ ì‹œ N/A ì²˜ë¦¬ (ì´ ë‹¨ì–´ ìˆ˜ë„ N/A)\n",
    "        print(\"{:<30} {:<10} {:<15} {:<15} {:<}\".format(\n",
    "            res[\"File\"], res[\"Status\"], \"N/A\", \"N/A\", res[\"Status\"]\n",
    "        ))\n",
    "print(\"-\" * 90)\n",
    "\n",
    "# ìµœì¢… ì „ì²´ ì´í•© ì¶œë ¥\n",
    "print(f\"ğŸ”¥ ëª¨ë“  íŒŒì¼ì˜ í‚¤ì›Œë“œ ì´í•© (ì „ì²´ ë°œìƒ íšŸìˆ˜): {grand_total_keywords} ê°œ\")\n",
    "print(f\"ğŸ”¥ ëª¨ë“  íŒŒì¼ì˜ ë°ì´í„° ì´ ë‹¨ì–´ ìˆ˜ (ì „ì²´ í•©ì‚°): {grand_total_words} ë‹¨ì–´\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849a4d20-c93c-49a6-8515-4cb863ff5c88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
